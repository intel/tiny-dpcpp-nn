from tiny_dpcpp_nn import Encoding
import torch
import numpy as np


def test_grid():

    scale = 1
    N_min = 16
    L = 16

    grid_encodings = Encoding(
        n_input_dims=3,
        encoding_config={
            "otype": "Grid",
            "type": "Hash",
            "n_levels": 16,
            "n_features_per_level": 2,
            "log2_hashmap_size": 19,
            "base_resolution": N_min,
            "per_level_scale": np.exp(np.log(2048 * scale / N_min) / (L - 1)),
            "interpolation": "Linear",
        },
    )

    input_encoding = torch.ones((10, 3)).to("xpu")
    output_encoding = grid_encodings(input_encoding)

    grid_output = torch.Tensor(
        [
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
            [
                1.1325e-05,
                -4.1187e-05,
                -7.4506e-06,
                -3.8445e-05,
                -5.7161e-05,
                3.1471e-05,
                -6.5804e-05,
                -4.4107e-06,
                -1.9014e-05,
                -2.9027e-05,
                -2.2352e-05,
                1.3053e-05,
                -4.7386e-05,
                -4.6253e-05,
                -2.3186e-05,
                8.4043e-06,
                2.6047e-05,
                5.0247e-05,
                -7.9870e-06,
                -1.0788e-05,
                -6.4373e-06,
                4.4703e-06,
                4.2915e-05,
                1.1921e-07,
                1.1027e-05,
                5.9605e-06,
                -2.9862e-05,
                1.4484e-05,
                4.4107e-06,
                -1.3649e-05,
                -2.5451e-05,
                2.4438e-06,
            ],
        ]
    ).to("xpu")
    assert torch.all(torch.isclose(output_encoding, grid_output, atol=1e-3))


def test_spherical():
    spherical_encodings = Encoding(
        n_input_dims=3,
        encoding_config={
            "otype": "SphericalHarmonics",
            "degree": 4,
        },
    )

    input_encoding = torch.ones((10, 3)).to("xpu")
    output_encoding = spherical_encodings(input_encoding)

    spherical_output = torch.Tensor(
        [
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
            [
                0.2821,
                -0.4886,
                0.4886,
                -0.4886,
                1.0925,
                -1.0925,
                0.6308,
                -1.0925,
                0.0000,
                -1.1801,
                2.8906,
                -1.8282,
                0.7464,
                -1.8282,
                0.0000,
                1.1801,
            ],
        ]
    ).to("xpu")
    assert torch.all(torch.isclose(output_encoding, spherical_output, atol=1e-3))


def test_identity():

    identity_encodings = Encoding(
        n_input_dims=3,
        encoding_config={
            "otype": "Identity",
            "scale": 1.0,
            "offset": 0.0,
        },
    )

    input_encoding = torch.ones((10, 3)).to("xpu")
    output_encoding = identity_encodings(input_encoding)

    assert torch.all(torch.isclose(input_encoding, output_encoding))


if __name__ == "__main__":
    test_identity()
    test_spherical()
    test_grid()
